{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Deep Reinforcement Learning Nanodegree\n",
    "\n",
    "## Project 3 (Collaboration and Competition)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Environment setup\n",
    "\n",
    "Run this notebook on root directory, following the instructions provided on README.md file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `env_filename` variable to point to the location of the Unity environment file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_filename = './Tennis_Linux_NoVis/Tennis.x86_64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=env_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agents and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agents' performance, if they select actions at random with each time step.  A window should pop up that allows you to observe the agents.\n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agents are able to use their experiences to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 1: 0.0\n",
      "Score (max over agents) from episode 2: 0.0\n",
      "Score (max over agents) from episode 3: 0.10000000149011612\n",
      "Score (max over agents) from episode 4: 0.09000000171363354\n",
      "Score (max over agents) from episode 5: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from collections import deque\n",
    "from ddpg_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDPG function\n",
    "\n",
    "def ddpg(agent, n_episodes=2500, max_t=1000, print_every=1):\n",
    "    \"\"\"Deep Deterministic Policy Gradient (DDPG)\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes  (int)   : maximum number of training episodes\n",
    "        max_t       (int)   : maximum number of timesteps per episode\n",
    "        print_every (int)   : interval to display results\n",
    "\n",
    "    \"\"\"\n",
    "    max_scores = []                               # list of max scores from each episode\n",
    "    moving_avgs = []                              # list of moving averages\n",
    "    best_score  = -np.inf\n",
    "    scores_window = deque(maxlen=100)              # mean scores from most recent 100 episodes\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]       # reset environment\n",
    "        states = env_info.vector_observations                   # get current state for each agent      \n",
    "        scores = np.zeros(num_agents)                           # initialize score for each agent\n",
    "        agent.reset()\n",
    "\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states, add_noise=True)  # select an action\n",
    "\n",
    "            env_info = env.step(actions)[brain_name]                    # send actions to environment\n",
    "            next_states = env_info.vector_observations                  # get next state\n",
    "            rewards = env_info.rewards                                  # get reward\n",
    "            dones = env_info.local_done                                 # see if episode has finished\n",
    "\n",
    "            # save experience to replay buffer, perform learning step at defined interval\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done, t)\n",
    "            states = next_states\n",
    "            scores += rewards        \n",
    "            if np.any(dones):                                   # exit loop when episode ends\n",
    "                break\n",
    "\n",
    "        max_scores.append(np.max(scores))           # save max score for the episode\n",
    "        scores_window.append(max_scores[-1])        # save max score to window\n",
    "        moving_avgs.append(np.mean(scores_window))  # save moving average\n",
    "\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {} > Max: {:.1f} \\t Moving Avg: {:.1f}'.format(str(i_episode).zfill(4),\n",
    "                                                                            max_scores[-1], moving_avgs[-1]))\n",
    "\n",
    "        if moving_avgs[-1] >= 0.5 and i_episode >= 100:\n",
    "            print('\\nEnvironment solved in {:d} episodes! Average Score: {:.2f}'.format(i_episode-100, moving_avgs[-1]))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break\n",
    "\n",
    "    return max_scores, moving_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0010 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0020 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0030 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0040 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0050 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0060 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0070 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0080 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0090 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0100 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0110 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0120 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0130 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0140 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0150 > Max: 0.1 \t Moving Avg: 0.0\n",
      "Episode 0160 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0170 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0180 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0190 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0200 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0210 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0220 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0230 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0240 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0250 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0260 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0270 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0280 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0290 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0300 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0310 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0320 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0330 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0340 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0350 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0360 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0370 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0380 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0390 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0400 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0410 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0420 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0430 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0440 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0450 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0460 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0470 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0480 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0490 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0500 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0510 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0520 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0530 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0540 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0550 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0560 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0570 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0580 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0590 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0600 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0610 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0620 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0630 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0640 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0650 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0660 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0670 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0680 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0690 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0700 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0710 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0720 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0730 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0740 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0750 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0760 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0770 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0780 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0790 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0800 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0810 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0820 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0830 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0840 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0850 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0860 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0870 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0880 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0890 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0900 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0910 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0920 > Max: 0.1 \t Moving Avg: 0.0\n",
      "Episode 0930 > Max: 0.0 \t Moving Avg: 0.0\n",
      "Episode 0940 > Max: 0.1 \t Moving Avg: 0.0\n",
      "Episode 0950 > Max: 0.1 \t Moving Avg: 0.0\n",
      "Episode 0960 > Max: 0.1 \t Moving Avg: 0.0\n",
      "Episode 0970 > Max: 0.1 \t Moving Avg: 0.0\n",
      "Episode 0980 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 0990 > Max: 0.0 \t Moving Avg: 0.1\n",
      "Episode 1000 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1010 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1020 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1030 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1040 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1050 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1060 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1070 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1080 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1090 > Max: 0.3 \t Moving Avg: 0.1\n",
      "Episode 1100 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1110 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1120 > Max: 0.1 \t Moving Avg: 0.1\n",
      "Episode 1130 > Max: 0.5 \t Moving Avg: 0.2\n",
      "Episode 1140 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1150 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1160 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1170 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1180 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1190 > Max: 0.3 \t Moving Avg: 0.2\n",
      "Episode 1200 > Max: 0.2 \t Moving Avg: 0.2\n",
      "Episode 1210 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1220 > Max: 0.3 \t Moving Avg: 0.2\n",
      "Episode 1230 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1240 > Max: 0.4 \t Moving Avg: 0.2\n",
      "Episode 1250 > Max: 0.3 \t Moving Avg: 0.2\n",
      "Episode 1260 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1270 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1280 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1290 > Max: 0.2 \t Moving Avg: 0.2\n",
      "Episode 1300 > Max: 0.3 \t Moving Avg: 0.2\n",
      "Episode 1310 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1320 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1330 > Max: 0.1 \t Moving Avg: 0.2\n",
      "Episode 1340 > Max: 0.2 \t Moving Avg: 0.2\n",
      "Episode 1350 > Max: 0.3 \t Moving Avg: 0.3\n",
      "Episode 1360 > Max: 0.0 \t Moving Avg: 0.3\n",
      "Episode 1370 > Max: 0.2 \t Moving Avg: 0.3\n",
      "Episode 1380 > Max: 0.7 \t Moving Avg: 0.3\n",
      "Episode 1390 > Max: 0.1 \t Moving Avg: 0.3\n",
      "Episode 1400 > Max: 0.0 \t Moving Avg: 0.3\n",
      "Episode 1410 > Max: 0.9 \t Moving Avg: 0.3\n",
      "Episode 1420 > Max: 1.2 \t Moving Avg: 0.4\n",
      "\n",
      "Environment solved in 1329 episodes! Average Score: 0.51\n"
     ]
    }
   ],
   "source": [
    "# run the training loop\n",
    "agent = Agent(state_size=state_size, action_size=action_size)\n",
    "scores, avgs = ddpg(agent, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores, label='DDPG')\n",
    "plt.plot(np.arange(len(scores)), avgs, c='r', label='Moving AVG')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.legend(loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
